{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "498cf93a-be6a-4f74-89be-d8f0212cc47f",
   "metadata": {},
   "source": [
    "# Изучение  процесса подбора гиперпараметров модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ed80e6-5b9a-4177-a83c-8c462bde81a2",
   "metadata": {},
   "source": [
    "## Подготовим среду и данные для выполнения заданий"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f617667-ac10-4ff9-917f-e9e942bc6597",
   "metadata": {},
   "source": [
    "### Загружаем датасет с информацией о медицинских параметрах больных диабетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d3c213-e9ed-4b13-93dd-c25b6d1b3c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/sasha/.cache/kagglehub/datasets/saurabh00007/diabetescsv/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"saurabh00007/diabetescsv\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0598dd6-4b09-46a2-b0c1-5cf6f52b3bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes.csv\n"
     ]
    }
   ],
   "source": [
    "!ls $path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "216f4e39-e194-4bb8-bd34-d28c8be92c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(path + '/diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acaecea8-f327-4609-a4ae-0612af2dfb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры датасета: (768, 9)\n"
     ]
    }
   ],
   "source": [
    "target = df['Outcome']\n",
    "print(f'Размеры датасета: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fb6e03e-0097-48b5-b868-4bd86faba3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('Outcome', axis=1)\n",
    "\n",
    "# Разделяем на train/test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, target, test_size=0.2, random_state=42, stratify=target  # сохраняем пропорции классов\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1349d1bf-ef02-4989-934d-9f4ed2a1ce90",
   "metadata": {},
   "source": [
    "## 1) Процесс подбора гиперпараметров используя Random Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f58f6589-a116-45a9-bcc5-4b9372b4f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Параметры для подбора\n",
    "param_dist = {\n",
    "    \"n_estimators\": [50, 100, 150, 200],\n",
    "    \"max_depth\": [None, 2, 4, 6, 8, 10],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Создаём модель\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,            # число случайных комбинаций\n",
    "    scoring='accuracy',   # метрика\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a09396-b3f6-4f06-9883-0f95c9816e35",
   "metadata": {},
   "source": [
    "### Обучаем модель с лучшими параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fef90567-8c56-41fe-b189-ff1164611e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Search best params: {'n_estimators': 150, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 6}\n",
      "Random Search best score: 0.7769425563108089\n",
      "Time taken (s): 7.36449670791626\n",
      "Test Accuracy: 0.7597402597402597\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "random_search.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Random Search best params:\", random_search.best_params_)\n",
    "print(\"Random Search best score:\", random_search.best_score_)\n",
    "print(\"Time taken (s):\", end - start)\n",
    "\n",
    "y_pred = random_search.best_estimator_.predict(X_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab01ae8-2957-4496-b18c-dc323afee7e6",
   "metadata": {},
   "source": [
    "## 2) TPE Search (Hyperopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3a53fd-7f09-4607-a94f-02af4ffbe77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52c07d4a-98ba-4351-817b-b5816c8213e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 20/20 [00:18<00:00,  1.08trial/s, best loss: -0.7834199653471945]\n",
      "Hyperopt best params: {'max_depth': np.int64(0), 'max_features': np.int64(0), 'min_samples_leaf': np.int64(2), 'min_samples_split': np.int64(2), 'n_estimators': np.int64(3)}\n",
      "Time taken (s): 18.49959087371826\n",
      "Hyperopt converted best params: {'n_estimators': 200, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 10, 'min_samples_leaf': 4}\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "n_estimators_list = [50, 100, 150, 200]\n",
    "max_depth_list = [None, 2, 4, 6, 8, 10]\n",
    "max_features_list = [\"sqrt\", \"log2\", None]\n",
    "min_samples_split_list = [2, 5, 10]\n",
    "min_samples_leaf_list = [1, 2, 4]\n",
    "\n",
    "# Пространство гиперпараметров\n",
    "space = {\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", n_estimators_list),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", max_depth_list),\n",
    "    \"max_features\": hp.choice(\"max_features\", max_features_list),\n",
    "    \"min_samples_split\": hp.choice(\"min_samples_split\", min_samples_split_list),\n",
    "    \"min_samples_leaf\": hp.choice(\"min_samples_leaf\", min_samples_leaf_list)\n",
    "}\n",
    "\n",
    "# Функция для минимизации (негативная точность, т.к. fmin минимизирует)\n",
    "def objective(params):\n",
    "    clf = RandomForestClassifier(random_state=42, **params)\n",
    "    score = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "start = time.time()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Hyperopt best params:\", best)\n",
    "print(\"Time taken (s):\", end - start)\n",
    "\n",
    "# Преобразуем индексы в значения параметров\n",
    "best_params = {\n",
    "    \"n_estimators\": n_estimators_list[best['n_estimators']],\n",
    "    \"max_depth\": max_depth_list[best['max_depth']],\n",
    "    \"max_features\": max_features_list[best['max_features']],\n",
    "    \"min_samples_split\": min_samples_split_list[best['min_samples_split']],\n",
    "    \"min_samples_leaf\": min_samples_leaf_list[best['min_samples_leaf']]\n",
    "}\n",
    "\n",
    "print(\"Hyperopt converted best params:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31909b3-5d67-44f1-903a-9b178428c473",
   "metadata": {},
   "source": [
    "### Обучаем модель с лучшими параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10d2053c-fda5-4bc9-b9f0-af5724b8e64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Hyperopt: 0.7532467532467533\n"
     ]
    }
   ],
   "source": [
    "best_rf = RandomForestClassifier(random_state=42, **best_params)\n",
    "best_rf.fit(X_train, y_train)\n",
    "y_pred = best_rf.predict(X_test)\n",
    "print(\"Test Accuracy Hyperopt:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29482070-55a8-448d-a61c-809897e5924b",
   "metadata": {},
   "source": [
    "## 3) Проанализируем полученные результаты\n",
    "Несмотря на то, что Hyperopt на этапе кросс-валидации показал чуть более высокий score, реальная точность на тестовой выборке оказалась ниже, чем у Random Search. Это может быть связано с ограниченным числом итераций и спецификой распределения гиперпараметров, что привело к переобучению на кросс-валидации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66a541e-df2b-4e05-9632-16005b0c790c",
   "metadata": {},
   "source": [
    "## Вывод: \n",
    "В данном случае Random Search оказался более эффективным, обеспечив лучшее качество на тестовых данных и быстрее завершив оптимизацию."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
